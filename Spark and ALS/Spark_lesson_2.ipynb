{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательная модель MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем сессию spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    # если вертуальной машине нельзя добавить памяти, можно использовать меньше\n",
    "    .config('spark_driver.memory', '4g')\n",
    "    # можно явно количество ядер, которые будет использовать Spark\n",
    "    # либо поставить звездочку для всех доступных виртуальной машине\n",
    "    .master('local[*]')\n",
    "    .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные из CSV\n",
    "# и преобразуем время проставления оценки из целого числа в дату со временем\n",
    "import os\n",
    "import pyspark.sql.functions as sql_func\n",
    "\n",
    "movies = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(os.path.join('data/movies.csv'), header=True, inferSchema=True)\n",
    "    .withColumn('genres_list', sql_func.split('genres', '\\|'))\n",
    "    .select('movieId', 'title', 'genres_list')\n",
    "    .cache()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>[Adventure, Children]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>[Action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>[Action, Adventure, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "5        6                         Heat (1995)   \n",
       "6        7                      Sabrina (1995)   \n",
       "7        8                 Tom and Huck (1995)   \n",
       "8        9                 Sudden Death (1995)   \n",
       "9       10                    GoldenEye (1995)   \n",
       "\n",
       "                                         genres_list  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1                     [Adventure, Children, Fantasy]  \n",
       "2                                  [Comedy, Romance]  \n",
       "3                           [Comedy, Drama, Romance]  \n",
       "4                                           [Comedy]  \n",
       "5                          [Action, Crime, Thriller]  \n",
       "6                                  [Comedy, Romance]  \n",
       "7                              [Adventure, Children]  \n",
       "8                                           [Action]  \n",
       "9                      [Action, Adventure, Thriller]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# взглянем внешне на датафрейм\n",
    "movies.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на общее распределение тегов\n",
    "# считываем csv никак не преобразую\n",
    "raw_tags = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(os.path.join('data/tags.csv'), header=True, inferSchema=True)\n",
    "    .cache()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Boxing story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>MMA</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>1445715205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>drugs</td>\n",
       "      <td>1445715054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>Leonardo DiCaprio</td>\n",
       "      <td>1445715051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>1445715056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>48516</td>\n",
       "      <td>way too long</td>\n",
       "      <td>1169687325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId                tag   timestamp\n",
       "0       2    60756              funny  1445714994\n",
       "1       2    60756    Highly quotable  1445714996\n",
       "2       2    60756       will ferrell  1445714992\n",
       "3       2    89774       Boxing story  1445715207\n",
       "4       2    89774                MMA  1445715200\n",
       "5       2    89774          Tom Hardy  1445715205\n",
       "6       2   106782              drugs  1445715054\n",
       "7       2   106782  Leonardo DiCaprio  1445715051\n",
       "8       2   106782    Martin Scorsese  1445715056\n",
       "9       7    48516       way too long  1169687325"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# взглянем внешне на датафрейм\n",
    "raw_tags.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ФИЛЬМОВ ВСЕГО: 9742\n",
      "ФИЛЬМОВ С ТЕГОМ: 1572\n",
      "РАЗЛИЧНЫХ ТЕГОВ 1589\n",
      "ВСЕГО СООТВЕТСТВИЯ ФИЛЬМ_ТЕГ: 3683\n",
      "ДОЛЯ НЕНУЛЕВЫХ ЭЛЕМЕНТОВ В МАТРИЦЕ ФИЛЬМ_ТЕГ 0.0014744338062090358\n"
     ]
    }
   ],
   "source": [
    "# протегированно чуть больше половина фильмов\n",
    "movie_tag_count = raw_tags.count()\n",
    "tag_count = raw_tags.select('tag').distinct().count()\n",
    "movie_count = raw_tags.select('movieId').distinct().count()\n",
    "\n",
    "print('ФИЛЬМОВ ВСЕГО:', movies.select('movieId').distinct().count())\n",
    "print('ФИЛЬМОВ С ТЕГОМ:', movie_count)\n",
    "print('РАЗЛИЧНЫХ ТЕГОВ', tag_count)\n",
    "print('ВСЕГО СООТВЕТСТВИЯ ФИЛЬМ_ТЕГ:', movie_tag_count)\n",
    "print('ДОЛЯ НЕНУЛЕВЫХ ЭЛЕМЕНТОВ В МАТРИЦЕ ФИЛЬМ_ТЕГ', \n",
    "     movie_tag_count / movie_count / tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РАЗЛИЧНЫХ ТЕГОВ БЕЗ УЧЕТА РЕГИСТРА: 1475\n"
     ]
    }
   ],
   "source": [
    "# некоторые теги различаются только регистром\n",
    "print('РАЗЛИЧНЫХ ТЕГОВ БЕЗ УЧЕТА РЕГИСТРА:', \n",
    "     raw_tags.select(sql_func.upper(sql_func.col('tag'))).distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# не будем интересоваться, какой именно пользователь поставил тег и когда это произошло\n",
    "tags = (\n",
    "    raw_tags\n",
    "    # теги могут различаться только регистром, поэтому привед их всех к верхниму\n",
    "    .select(sql_func.col('movieId'),\n",
    "    sql_func.upper(sql_func.col('tag')).alias('tag')\n",
    "    )\n",
    "    .groupBy('movieId')\n",
    "    .agg(sql_func.collect_list('tag').alias('tags_list')) # собирает все теги в виде списка\n",
    "    .join(movies, 'movieId', 'right')                     # right чтобы у всех фильмов были теги\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tags_list</th>\n",
       "      <th>title</th>\n",
       "      <th>genres_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[PIXAR, PIXAR, FUN]</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[GAME, FANTASY, MAGIC BOARD GAME, ROBIN WILLIAMS]</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[MOLDY, OLD]</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[PREGNANCY, REMAKE]</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[REMAKE]</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>[Adventure, Children]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>[Action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>[Action, Adventure, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                          tags_list  \\\n",
       "0        1                                [PIXAR, PIXAR, FUN]   \n",
       "1        2  [GAME, FANTASY, MAGIC BOARD GAME, ROBIN WILLIAMS]   \n",
       "2        3                                       [MOLDY, OLD]   \n",
       "3        4                                               None   \n",
       "4        5                                [PREGNANCY, REMAKE]   \n",
       "5        6                                               None   \n",
       "6        7                                           [REMAKE]   \n",
       "7        8                                               None   \n",
       "8        9                                               None   \n",
       "9       10                                               None   \n",
       "\n",
       "                                title  \\\n",
       "0                    Toy Story (1995)   \n",
       "1                      Jumanji (1995)   \n",
       "2             Grumpier Old Men (1995)   \n",
       "3            Waiting to Exhale (1995)   \n",
       "4  Father of the Bride Part II (1995)   \n",
       "5                         Heat (1995)   \n",
       "6                      Sabrina (1995)   \n",
       "7                 Tom and Huck (1995)   \n",
       "8                 Sudden Death (1995)   \n",
       "9                    GoldenEye (1995)   \n",
       "\n",
       "                                         genres_list  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1                     [Adventure, Children, Fantasy]  \n",
       "2                                  [Comedy, Romance]  \n",
       "3                           [Comedy, Drama, Romance]  \n",
       "4                                           [Comedy]  \n",
       "5                          [Action, Crime, Thriller]  \n",
       "6                                  [Comedy, Romance]  \n",
       "7                              [Adventure, Children]  \n",
       "8                                           [Action]  \n",
       "9                      [Action, Adventure, Thriller]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Boxing story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>MMA</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>1445715205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>drugs</td>\n",
       "      <td>1445715054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>Leonardo DiCaprio</td>\n",
       "      <td>1445715051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>1445715056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>48516</td>\n",
       "      <td>way too long</td>\n",
       "      <td>1169687325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId                tag   timestamp\n",
       "0       2    60756              funny  1445714994\n",
       "1       2    60756    Highly quotable  1445714996\n",
       "2       2    60756       will ferrell  1445714992\n",
       "3       2    89774       Boxing story  1445715207\n",
       "4       2    89774                MMA  1445715200\n",
       "5       2    89774          Tom Hardy  1445715205\n",
       "6       2   106782              drugs  1445715054\n",
       "7       2   106782  Leonardo DiCaprio  1445715051\n",
       "8       2   106782    Martin Scorsese  1445715056\n",
       "9       7    48516       way too long  1169687325"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вариант написания кода в синтаксесе SQL\n",
    "raw_tags.createOrReplaceTempView('raw_tags') # регистрация таблицы для доступа в SQL запросах\n",
    "\n",
    "spark.sql('''\n",
    "SELECT * FROM raw_tags\n",
    "''').limit(10).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collect_list(tag)</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hula hoop]</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[dance, music]</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[aliens]</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[lawyers]</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[adultery, Africa]</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Stephen King]</td>\n",
       "      <td>2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[spoof]</td>\n",
       "      <td>3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[In Netflix queue]</td>\n",
       "      <td>6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[cancer]</td>\n",
       "      <td>6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Nick and Nora Charles]</td>\n",
       "      <td>7833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         collect_list(tag)  movieId\n",
       "0              [hula hoop]      471\n",
       "1           [dance, music]     1088\n",
       "2                 [aliens]     1580\n",
       "3                [lawyers]     1645\n",
       "4       [adultery, Africa]     1959\n",
       "5           [Stephen King]     2122\n",
       "6                  [spoof]     3175\n",
       "7       [In Netflix queue]     6466\n",
       "8                 [cancer]     6620\n",
       "9  [Nick and Nora Charles]     7833"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# еще вариант написания кода в синтаксесе SQL\n",
    "spark.sql('''\n",
    "SELECT \n",
    "COLLECT_LIST (tag),\n",
    "movieId FROM raw_tags\n",
    "GROUP BY movieId\n",
    "''').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим теги и жанры в единое пространство\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "# B Spark нет некотрых полезных функций, но можно создать свои\n",
    "#  в частности, мы хотим привести все жанры также в верхниму регистру\n",
    "list_concat = sql_func.udf(\n",
    "    lambda one_list, another_list:\n",
    "        [str.upper(elem) for elem in one_list] + (another_list if another_list else []), # первый список - это список жанров\n",
    "    returnType=ArrayType(StringType()) # возврат строк (тип указан явно)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение жанров и тегов в один столбец (полный мешок слов)\n",
    "content_features = (\n",
    "    tags\n",
    "    .select('movieId', 'title', \n",
    "           list_concat('genres_list', 'tags_list').alias('content_features'))\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>content_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[ADVENTURE, ANIMATION, CHILDREN, COMEDY, FANTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[ADVENTURE, CHILDREN, FANTASY, GAME, FANTASY, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[COMEDY, ROMANCE, MOLDY, OLD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[COMEDY, DRAMA, ROMANCE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[COMEDY, PREGNANCY, REMAKE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>[ACTION, CRIME, THRILLER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>[COMEDY, ROMANCE, REMAKE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>[ADVENTURE, CHILDREN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>[ACTION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>[ACTION, ADVENTURE, THRILLER]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "5        6                         Heat (1995)   \n",
       "6        7                      Sabrina (1995)   \n",
       "7        8                 Tom and Huck (1995)   \n",
       "8        9                 Sudden Death (1995)   \n",
       "9       10                    GoldenEye (1995)   \n",
       "\n",
       "                                    content_features  \n",
       "0  [ADVENTURE, ANIMATION, CHILDREN, COMEDY, FANTA...  \n",
       "1  [ADVENTURE, CHILDREN, FANTASY, GAME, FANTASY, ...  \n",
       "2                      [COMEDY, ROMANCE, MOLDY, OLD]  \n",
       "3                           [COMEDY, DRAMA, ROMANCE]  \n",
       "4                        [COMEDY, PREGNANCY, REMAKE]  \n",
       "5                          [ACTION, CRIME, THRILLER]  \n",
       "6                          [COMEDY, ROMANCE, REMAKE]  \n",
       "7                              [ADVENTURE, CHILDREN]  \n",
       "8                                           [ACTION]  \n",
       "9                      [ACTION, ADVENTURE, THRILLER]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_features.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>content_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4896</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "      <td>[ADVENTURE, CHILDREN, FANTASY, MAGIC, WIZARDS,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title  \\\n",
       "0     4896  Harry Potter and the Sorcerer's Stone (a.k.a. ...   \n",
       "\n",
       "                                    content_features  \n",
       "0  [ADVENTURE, CHILDREN, FANTASY, MAGIC, WIZARDS,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# например Гарри Поттер и философский камень\n",
    "content_features.where('movieId==4896').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGIC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADVENTURE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHILDREN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WIZARDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HARRY POTTER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FANTASY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EVERYTHING YOU WANT IS HERE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HUMOROUS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALAN RICKMAN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         words  freq\n",
       "0                        MAGIC     2\n",
       "1                    ADVENTURE     1\n",
       "2                     CHILDREN     1\n",
       "3                      WIZARDS     1\n",
       "4                 HARRY POTTER     1\n",
       "5                      FANTASY     1\n",
       "6  EVERYTHING YOU WANT IS HERE     1\n",
       "7                     HUMOROUS     1\n",
       "8                 ALAN RICKMAN     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# мешок слов (bag-of-words)\n",
    "from pyspark.sql.functions import explode, count, desc\n",
    "\n",
    "(\n",
    "content_features\n",
    "    .where('movieId==4896')\n",
    "    .select(explode('content_features').alias('words'))\n",
    "    .groupBy('words')\n",
    "    .agg(count('words').alias('freq'))\n",
    "    .orderBy(desc('freq'))\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь фичи есть для всех фильмов\n",
    "content_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем частоты встречаемости для тегов для всех фильмов\n",
    "from pyspark.ml.feature import HashingTF\n",
    "\n",
    "term_frequencies = HashingTF(\n",
    "    # от каждого тега будет вычислен хэш\n",
    "    # и по факту мы будем считать частоты бакетов хэшей, а не самих тегов\n",
    "    numFeatures = 512, inputCol='content_features', \n",
    "    outputCol='term_frequencies').transform(content_features).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(512, {6: 1.0, 99: 1.0, 113: 1.0, 172: 2.0, 241: 1.0, 309: 1.0, 344: 1.0, 402: 1.0, 404: 1.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пример частот встречаемости бакетов (хранится в виде разряженного вектора)\n",
    "term_frequencies.where('movieId==4896').first().term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь сделаем поправку на частоту тегов в целом, чтобы убрать неиформативные теги \n",
    "# это второй шаг TF-IDF (term frequency, inverted document frequency)\n",
    "from pyspark.ml.feature import IDF # IDF = ln(N+1 / n+1) N - общее кол-во фильмов, n - кол-во фильмов где есть этот тег\n",
    "\n",
    "idf_model = IDF(inputCol='term_frequencies', outputCol='tf_idf',\n",
    "                minDocFreq=2).fit(term_frequencies) # частота 2, чтобы выкинуть теги которые есть только у одного фильма\n",
    "\n",
    "tf_idf = (idf_model.transform(term_frequencies)\n",
    "         .select('movieId', 'title', 'tf_idf')\n",
    "         .cache()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.10486282, 6.00625053, 0.        , 5.96542853, 6.88171926,\n",
       "       8.08569207, 2.03753218, 0.        , 0.        , 7.79801   ,\n",
       "       7.39254489, 7.79801   , 0.        , 7.23839421, 6.88171926,\n",
       "       6.88171926, 7.57486644, 7.79801   , 6.98707978, 0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сами инвертированные частоты термов\n",
    "idf_model.idf[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(512, {6: 2.0375, 99: 2.525, 113: 7.3925, 172: 14.2097, 241: 7.3925, 309: 6.2399, 344: 0.0, 402: 2.6755, 404: 6.3511})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# результат TF-IDF преобразования для выбранного фильма\n",
    "tf_idf.where('movieId==4896').first().tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#сохранение json файла\n",
    "#tf_idf.coalesce(1).write.mode('Overwrite').json(os.path.join('data/tf_idf.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная работа\n",
    "1. Получить гистограмму количества тегов у фильма\n",
    "2. Получить гистограмму количества тегов у пользователя\n",
    "3. Получить количества тегов по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tags.createOrReplaceTempView('raw_tags')\n",
    "y = spark.sql('''\n",
    "    Select Distinct \n",
    "        Percentile(tag_count, array(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))\n",
    "    From(\n",
    "        Select userId, \n",
    "        \n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Построим профиль пользователя по истории действий пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(os.path.join('data/ratings.csv'), header=True, inferSchema=True)\n",
    "    # если используется меньше памяти, то здесь можно взять не все данные, а небольшую выборку\n",
    "    # даже при fraction=0.01  качественная картина не меняется\n",
    "    .sample(withReplacement=False, fraction=1.0, seed = 0)\n",
    "    .withColumn('rating_datatime', sql_func.from_unixtime('timestamp'))\n",
    "    .drop('timestamp')\n",
    "    .cache()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# файл с фильмами небольшой, так что его можно читать полностью\n",
    "# даже если памяти доступно немного\n",
    "movies_genres = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(os.path.join('data/movies.csv'), header=True, inferSchema=True)\n",
    "    # парсим информацию о жанрах\n",
    "    .withColumn('genres_array', sql_func.split('genres', '\\|'))\n",
    "    .select('movieId', sql_func.explode('genres_array').alias('genre')) # explode превращает строку с одинм списком \n",
    "    .cache()                                                            # во мнжество строк\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22079</th>\n",
       "      <td>193583</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22080</th>\n",
       "      <td>193585</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22081</th>\n",
       "      <td>193587</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22082</th>\n",
       "      <td>193587</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22083</th>\n",
       "      <td>193609</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22084 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId      genre\n",
       "0            1  Adventure\n",
       "1            1  Animation\n",
       "2            1   Children\n",
       "3            1     Comedy\n",
       "4            1    Fantasy\n",
       "...        ...        ...\n",
       "22079   193583    Fantasy\n",
       "22080   193585      Drama\n",
       "22081   193587     Action\n",
       "22082   193587  Animation\n",
       "22083   193609     Comedy\n",
       "\n",
       "[22084 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получим соответствие жанров фильмам: много жанров - один фильм\n",
    "movies_genres.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ФИЛЬМОВ С ЖАНРАМИ:  9742\n",
      "ФИЛЬМОВ С ОЦЕНКАМИ:  9724\n"
     ]
    }
   ],
   "source": [
    "# у нас есть фильмы без оценок\n",
    "print(\"ФИЛЬМОВ С ЖАНРАМИ: \", movies_genres.select ('movieID').distinct().count())\n",
    "print(\"ФИЛЬМОВ С ОЦЕНКАМИ: \", ratings.select ('movieID').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  создаем профиль пользователя (жанровые предпочтения):\n",
    "# набор средних оценок фильмов одного жанра\n",
    "user_profiles = (\n",
    "    ratings\n",
    "    .join(movies_genres, 'movieId')\n",
    "    .groupBy('userId', 'genre')\n",
    "    .agg(sql_func.avg('rating').alias('genry_rating')) # средняя оценка фильмов в жанрах, которые предпочитает пользователь\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------------+\n",
      "|userId|    genre|      genry_rating|\n",
      "+------+---------+------------------+\n",
      "|    15|      War|               4.1|\n",
      "|    15|  Romance|3.8846153846153846|\n",
      "|    15|   Horror|3.8181818181818183|\n",
      "|    15|    Drama| 3.740740740740741|\n",
      "|    15|   Sci-Fi|3.5847457627118646|\n",
      "|    15|    Crime|3.5789473684210527|\n",
      "|    15| Thriller|3.4318181818181817|\n",
      "|    15|  Mystery|3.4166666666666665|\n",
      "|    15|   Comedy| 3.357142857142857|\n",
      "|    15|Adventure|3.3421052631578947|\n",
      "|    15|     IMAX|3.3055555555555554|\n",
      "|    15|   Action|3.2033898305084745|\n",
      "|    15|Animation|2.9545454545454546|\n",
      "|    15|  Fantasy|           2.90625|\n",
      "|    15|  Musical|               2.7|\n",
      "|    15| Children|2.6904761904761907|\n",
      "|    15|  Western|               2.5|\n",
      "+------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# посмотрим как выглядит профиль одного из пользователей\n",
    "(\n",
    "    user_profiles\n",
    "    .where('userId==15')\n",
    "    .orderBy(sql_func.desc('genry_rating'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказываем  оценку фильма как среднее по средним оценкам жанров данного пользователя\n",
    "predictions = (\n",
    "    ratings\n",
    "    .join(movies_genres, 'movieId', 'left')\n",
    "    .join(user_profiles, ['userId', 'genre'], 'left')\n",
    "    .groupBy('userId', 'movieId', 'rating')\n",
    "    .agg(sql_func.avg('genry_rating').alias('prediction'))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+------------------+\n",
      "|userId|movieId|rating|        prediction|\n",
      "+------+-------+------+------------------+\n",
      "|     1|    441|   4.0|  4.27710843373494|\n",
      "|     3|   2080|   0.5|             0.625|\n",
      "|     4|    708|   4.0| 3.444462864721485|\n",
      "|     4|   3489|   1.0|3.6163327749080927|\n",
      "|     6|    248|   5.0|  3.37007874015748|\n",
      "|    10|   2571|   0.5| 2.858974358974359|\n",
      "|    10|   8961|   2.5| 3.564055493981995|\n",
      "|    11|    529|   5.0| 4.166666666666667|\n",
      "|    11|   1518|   4.0|3.5998641304347827|\n",
      "|    11|   1784|   5.0| 3.938034188034188|\n",
      "|    12|   1721|   5.0| 4.566964285714286|\n",
      "|    16|    111|   4.5|  3.75742337164751|\n",
      "|    18|    593|   4.5|3.6758940056598917|\n",
      "|    18|   1206|   4.5| 3.815771630183201|\n",
      "|    18|   7147|   4.5|3.7401814546309957|\n",
      "|    18|  84392|   4.5|3.8740591432745712|\n",
      "|    19|    745|   4.0|2.7579300238613964|\n",
      "|    19|   1580|   2.0|2.6419778083295142|\n",
      "|    19|   1689|   2.0|  2.69659581584869|\n",
      "|    19|   2081|   4.0| 2.758146477406793|\n",
      "+------+-------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание слушателям\n",
    "Самостоятельно найти RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-64-ce07abeb2e4e>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-ce07abeb2e4e>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "RMSE = np.sqrt(\n",
    "    predictions\n",
    "    .select(\n",
    "        sql_func(pow(predictions.prediction - predictions.rating, 2)\n",
    "        .alias('sq_error'))\n",
    "    .agg(sql_func.avg('sq_error'))\n",
    "    .first()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CONTENT-BASED МОДЕЛЬ (слайды)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              tf_idf|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|(512,[6,99,229,24...|\n",
      "|      2|      Jumanji (1995)|(512,[3,4,6,99,34...|\n",
      "|      3|Grumpier Old Men ...|(512,[104,229,312...|\n",
      "|      4|Waiting to Exhale...|(512,[229,343,434...|\n",
      "|      5|Father of the Bri...|(512,[69,229,391]...|\n",
      "|      6|         Heat (1995)|(512,[263,387,456...|\n",
      "|      7|      Sabrina (1995)|(512,[229,343,391...|\n",
      "|      8| Tom and Huck (1995)|(512,[6,402],[2.0...|\n",
      "|      9| Sudden Death (1995)|(512,[387],[1.670...|\n",
      "|     10|    GoldenEye (1995)|(512,[6,263,387],...|\n",
      "|     11|American Presiden...|(512,[70,229,343,...|\n",
      "|     12|Dracula: Dead and...|(512,[229,462],[0...|\n",
      "|     13|        Balto (1995)|(512,[6,337,402],...|\n",
      "|     14|        Nixon (1995)|(512,[70,378,434]...|\n",
      "|     15|Cutthroat Island ...|(512,[6,343,387],...|\n",
      "|     16|       Casino (1995)|(512,[194,434,456...|\n",
      "|     17|Sense and Sensibi...|(512,[343,434,486...|\n",
      "|     18|   Four Rooms (1995)|(512,[229],[0.952...|\n",
      "|     19|Ace Ventura: When...|(512,[229],[0.952...|\n",
      "|     20|  Money Train (1995)|(512,[229,263,387...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# не будем использовать модели из SPark, а используем модели из Sklearn\n",
    "# для распределения нагрузки под управлением spark создаем пользовательскую функцию\n",
    "\n",
    "from sklearn.linear_model import ElasticNet        # линейная модель с регуляризацией\n",
    "from pyspark.sql.types import FloatType, ArrayType\n",
    "\n",
    "def sklearn_lr(spark_x: list, spark_y: list) -> list:\n",
    "    '''\n",
    "    spark_x: СПИСОК pyspark.ml.linalg.SparseVector - фичи для регрессии\n",
    "    spark_y: СПИСОК ЗНАЧЕНИЙ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ РЕГРЕССИИ\n",
    "    return: СПИСОК КОЭФФИЦИЕНТОВ РЕГРЕСИИ\n",
    "    '''\n",
    "    # переводим данные из формата Spark в удобный для Sklearn\n",
    "    X = np.array([vector.toArray() for vector in spark_x])\n",
    "    y = np.array(spark_y).reshape(-1, 1)\n",
    "    # применяем модель ElasticNet из Sklearn \n",
    "    lr = ElasticNet().fit(X, y)\n",
    "    # возвращаем в ответе плотный вектор коэффициентов регрессии\n",
    "    return [lr.sparse_coef_.todense().tolist()[0], lr.intercept_.tolist()]\n",
    "\n",
    "# определяем Spark UDF, которая обучает регрессию на своих аргументах\n",
    "reg_udf = sql_func.udf(sklearn_lr, returnType=ArrayType(ArrayType(FloatType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "# разбиваем полученные данные на обучающую и тестовую выборки\n",
    "\n",
    "%time\n",
    "X_train, X_test = ratings.join(tf_idf, 'movieId').randomSplit([0.8, 0.2], seed=42)\n",
    "X_train.cache()\n",
    "X_test.cache()\n",
    "\n",
    "\n",
    "#строим для каждого пользователя свою модель регрессии\n",
    "model_coef = (\n",
    "    X_train\n",
    "    .groupBy('userId')\n",
    "    .agg(\n",
    "        sql_func.collect_list('tf_idf').alias('X'),\n",
    "        sql_func.collect_list('rating').alias('y')\n",
    "    )\n",
    "    .withColumn('model_coef', reg_udf('X', 'y')) # к каждой строчке применить функцию пользовательскую\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем полцученные коэффициенты регрессии на диск\n",
    "# model_coef.write.mode('Overwrite').parquet(os.path.join('data/model_coef.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 ms, sys: 13.3 ms, total: 34.1 ms\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_coef.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|userId|                   X|                   y|          model_coef|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|   148|[(512,[88,90,187,...|[4.0, 3.0, 4.0, 3...|[[0.0, 0.0, 0.0, ...|\n",
      "|   463|[(512,[0,3,4,9,15...|[4.0, 4.0, 4.0, 3...|[[0.0, 0.0, 0.0, ...|\n",
      "|   471|[(512,[6,99,229,2...|[5.0, 4.0, 3.0, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|   496|[(512,[6,187,229,...|[1.0, 5.0, 4.5, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|   243|[(512,[6,263,387]...|[5.0, 4.0, 4.0, 5...|[[0.0, 0.0, 0.0, ...|\n",
      "|   392|[(512,[324,343,43...|[3.0, 1.0, 2.0, 3...|[[0.0, 0.0, 0.0, ...|\n",
      "|   540|[(512,[263,385,41...|[4.5, 3.5, 5.0, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|    31|[(512,[69,229,391...|[3.0, 4.0, 4.0, 3...|[[0.0, 0.0, 0.0, ...|\n",
      "|   516|[(512,[6,29,35,66...|[5.0, 4.0, 4.0, 3...|[[0.0, 0.0, 0.0, ...|\n",
      "|    85|[(512,[6,434],[2....|[5.0, 5.0, 4.0, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|   137|[(512,[10,52,143,...|[4.0, 5.0, 5.0, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|   251|[(512,[263,385,41...|[5.0, 4.5, 5.0, 5...|[[0.0, 0.0, 0.0, ...|\n",
      "|   451|[(512,[69,229,391...|[3.0, 4.0, 5.0, 5...|[[0.0, 0.0, 0.0, ...|\n",
      "|   580|[(512,[6,99,229,2...|[3.0, 4.0, 3.5, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|    65|[(512,[67,78,122,...|[4.0, 4.0, 3.0, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|   458|[(512,[69,229,391...|[3.0, 4.0, 5.0, 5...|[[0.0, 0.0, 0.0, ...|\n",
      "|    53|[(512,[229],[0.95...|[5.0, 5.0, 5.0, 5...|[[0.0, 0.0, 0.0, ...|\n",
      "|   255|[(512,[93,282,402...|[1.0, 2.0, 5.0, 5...|[[0.0, 0.0, 0.0, ...|\n",
      "|   481|[(512,[62,208,343...|[4.0, 2.0, 2.0, 4...|[[0.0, 0.0, 0.0, ...|\n",
      "|   588|[(512,[263,387,45...|[5.0, 3.0, 4.0, 2...|[[0.0, 0.0, 0.0, ...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ввиду применение регуляризации, среди коэффициентов много нулей\n",
    "model_coef.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перемножение векторного представления фильма и векторного представления пользователя\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "\n",
    "def lr_apply (x: SparseVector, lr_coef: list) -> float:\n",
    "    '''\n",
    "    param x ВЕКТОР ФИЧ ДЛЯ РЕГРЕССИИ\n",
    "    param lr_coef\n",
    "    return: ПРЕДСКАЗАННОЕ МОДЕЛЬЮ РЕГРЕССИИ ЗНАЧЕНИЕ\n",
    "    '''\n",
    "    return float(np.array(x).dot(np.array(lr_coef[0])) + lr_coef[1][0])\n",
    "\n",
    "lr_apply_udf = sql_func.udf(lr_apply, returnType=FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция предсказание\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def get_prediction(data: DataFrame) ->DataFrame:\n",
    "    return (\n",
    "        data\n",
    "        .join(model_coef, 'userId')\n",
    "        .select('userId', 'rating', 'movieId', 'tf_idf', lr_apply_udf('tf_idf', 'model_coef').alias('prediction'))\n",
    "        .cache()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 4.5 ms, total: 18.3 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# предсказание на трэйне\n",
    "train_prediction = get_prediction(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем предсказания на диск\n",
    "\n",
    "# train_prediction.write.mode('Overwrite').parquet(os.path.join('data/train_prediction.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+--------------------+----------+\n",
      "|userId|rating|movieId|              tf_idf|prediction|\n",
      "+------+------+-------+--------------------+----------+\n",
      "|     1|   4.0|      1|(512,[6,99,229,24...| 4.3707867|\n",
      "|    17|   4.5|      1|(512,[6,99,229,24...| 4.1896553|\n",
      "|    18|   3.5|      1|(512,[6,99,229,24...| 3.7066014|\n",
      "|    19|   4.0|      1|(512,[6,99,229,24...| 2.6095765|\n",
      "|    21|   3.5|      1|(512,[6,99,229,24...|  3.298365|\n",
      "|    27|   3.0|      1|(512,[6,99,229,24...| 3.5607476|\n",
      "|    31|   5.0|      1|(512,[6,99,229,24...|  3.871795|\n",
      "|    32|   3.0|      1|(512,[6,99,229,24...| 3.7560976|\n",
      "|    33|   3.0|      1|(512,[6,99,229,24...|    3.8125|\n",
      "|    40|   5.0|      1|(512,[6,99,229,24...|    3.7125|\n",
      "|    44|   3.0|      1|(512,[6,99,229,24...| 3.2521224|\n",
      "|    45|   4.0|      1|(512,[6,99,229,24...|  3.863344|\n",
      "|    50|   3.0|      1|(512,[6,99,229,24...| 2.7935605|\n",
      "|    54|   3.0|      1|(512,[6,99,229,24...| 3.0833333|\n",
      "|    57|   5.0|      1|(512,[6,99,229,24...| 3.4025974|\n",
      "|    63|   5.0|      1|(512,[6,99,229,24...| 3.6126127|\n",
      "|    64|   4.0|      1|(512,[6,99,229,24...| 3.7813954|\n",
      "|    66|   4.0|      1|(512,[6,99,229,24...|  4.013011|\n",
      "|    68|   2.5|      1|(512,[6,99,229,24...| 3.2283266|\n",
      "|    71|   5.0|      1|(512,[6,99,229,24...| 3.9159698|\n",
      "+------+------+-------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели при помощи RMSE\n",
    "def evaluate_prediction(prediction: DataFrame) -> float:\n",
    "    return np.sqrt(\n",
    "        prediction\n",
    "        .selectExpr('''\n",
    "            CASE\n",
    "                WHEN prediction > 5 THEN 5\n",
    "                WHEN prediction < 0.5 THEN 0.5\n",
    "                ELSE prediction\n",
    "            END AS prediction\n",
    "        ''', 'rating')\n",
    "        .select(\n",
    "            sql_func.pow(sql_func.col('rating') - sql_func.col('prediction'), 2)\n",
    "            .alias('squared_error')\n",
    "        )\n",
    "        .agg(sql_func.avg('squared_error'))\n",
    "        .first()[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261553578265541"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оценка на трейне\n",
    "evaluate_prediction(train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.71 ms, sys: 4.06 ms, total: 12.8 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# предсказание на тесте\n",
    "test_prediction = get_prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9378773706354082"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оценка на тесте\n",
    "evaluate_prediction(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Item-to-Item рекомендация (слайд)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# определим функцию расстояния\n",
    "distance = sql_func.udf(\n",
    "    lambda x1, x2: euclidean(\n",
    "        x1.toArray(),\n",
    "        x2.toArray()\n",
    "        ), # тут может потребоваться tolist() для некоторых расстояний\n",
    "    returnType=FloatType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# находим матрицу расстояний (ленивые вычисления, это только граф, т.к. помрет на большой матрице :)\n",
    "distance_matrix = (\n",
    "    tf_idf.alias('one')\n",
    "    .crossJoin(tf_idf.alias('two'))\n",
    "    .select(\n",
    "        'one.movieId',\n",
    "        'one.title',\n",
    "        'two.movieId',\n",
    "        'two.title',\n",
    "        distance('one.tf_idf', 'two.tf_idf').alias('distance')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4896</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5816</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "      <td>13.840505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8368</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (2004)</td>\n",
       "      <td>14.439393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40815</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (2005)</td>\n",
       "      <td>14.531631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8943</td>\n",
       "      <td>Being Julia (2004)</td>\n",
       "      <td>16.071344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>117887</td>\n",
       "      <td>Paddington (2014)</td>\n",
       "      <td>19.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3967</td>\n",
       "      <td>Billy Elliot (2000)</td>\n",
       "      <td>19.195896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>329</td>\n",
       "      <td>Star Trek: Generations (1994)</td>\n",
       "      <td>19.225018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2694</td>\n",
       "      <td>Big Daddy (1999)</td>\n",
       "      <td>19.239136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>104218</td>\n",
       "      <td>Grown Ups 2 (2013)</td>\n",
       "      <td>19.239136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title   distance\n",
       "0     4896  Harry Potter and the Sorcerer's Stone (a.k.a. ...   0.000000\n",
       "1     5816     Harry Potter and the Chamber of Secrets (2002)  13.840505\n",
       "2     8368    Harry Potter and the Prisoner of Azkaban (2004)  14.439393\n",
       "3    40815         Harry Potter and the Goblet of Fire (2005)  14.531631\n",
       "4     8943                                 Being Julia (2004)  16.071344\n",
       "5   117887                                  Paddington (2014)  19.015400\n",
       "6     3967                                Billy Elliot (2000)  19.195896\n",
       "7      329                      Star Trek: Generations (1994)  19.225018\n",
       "8     2694                                   Big Daddy (1999)  19.239136\n",
       "9   104218                                 Grown Ups 2 (2013)  19.239136"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# находим 10 ближайших соседей Гарри Потера\n",
    "(\n",
    "distance_matrix\n",
    "    .where(sql_func.col('one.movieId')==4896)\n",
    "    .orderBy('distance')\n",
    "    .select('two.movieId', 'two.title', 'distance')\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### САМОСТОЯТЕЛЬНАЯ РАБОТА (СЛАЙД)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|         genres_list|\n",
      "+-------+--------------------+--------------------+\n",
      "|    778|Trainspotting (1996)|[Comedy, Crime, D...|\n",
      "| 168266|T2: Trainspotting...|      [Crime, Drama]|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.where(\"title LIKE '%Trainspotting%'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778</td>\n",
       "      <td>Trainspotting (1996)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104863</td>\n",
       "      <td>What If (2013)</td>\n",
       "      <td>11.870906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4623</td>\n",
       "      <td>Major League (1989)</td>\n",
       "      <td>12.076021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5139</td>\n",
       "      <td>Bad News Bears, The (1976)</td>\n",
       "      <td>12.076021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>956</td>\n",
       "      <td>Penny Serenade (1941)</td>\n",
       "      <td>12.220367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1302</td>\n",
       "      <td>Field of Dreams (1989)</td>\n",
       "      <td>12.634316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5644</td>\n",
       "      <td>Pride of the Yankees, The (1942)</td>\n",
       "      <td>13.579036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4410</td>\n",
       "      <td>Something Wild (1986)</td>\n",
       "      <td>13.627515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>166</td>\n",
       "      <td>Doom Generation, The (1995)</td>\n",
       "      <td>13.627515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>478</td>\n",
       "      <td>Jimmy Hollywood (1994)</td>\n",
       "      <td>13.627515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                             title   distance\n",
       "0      778              Trainspotting (1996)   0.000000\n",
       "1   104863                    What If (2013)  11.870906\n",
       "2     4623               Major League (1989)  12.076021\n",
       "3     5139        Bad News Bears, The (1976)  12.076021\n",
       "4      956             Penny Serenade (1941)  12.220367\n",
       "5     1302            Field of Dreams (1989)  12.634316\n",
       "6     5644  Pride of the Yankees, The (1942)  13.579036\n",
       "7     4410             Something Wild (1986)  13.627515\n",
       "8      166       Doom Generation, The (1995)  13.627515\n",
       "9      478            Jimmy Hollywood (1994)  13.627515"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "distance_matrix\n",
    "    .where(sql_func.col('one.movieId')==778)\n",
    "    .orderBy('distance')\n",
    "    .select('two.movieId', 'two.title', 'distance')\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104863</td>\n",
       "      <td>What If (2013)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>Reality Bites (1994)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>542</td>\n",
       "      <td>Son in Law (1993)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883</td>\n",
       "      <td>Bulworth (1998)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175</td>\n",
       "      <td>Delicatessen (1991)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>94</td>\n",
       "      <td>Beautiful Girls (1996)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>803</td>\n",
       "      <td>Walking and Talking (1996)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>195</td>\n",
       "      <td>Something to Talk About (1995)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1457</td>\n",
       "      <td>Fools Rush In (1997)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1784</td>\n",
       "      <td>As Good as It Gets (1997)</td>\n",
       "      <td>7.238394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                           title  distance\n",
       "0   104863                  What If (2013)  0.000000\n",
       "1      372            Reality Bites (1994)  7.238394\n",
       "2      542               Son in Law (1993)  7.238394\n",
       "3     1883                 Bulworth (1998)  7.238394\n",
       "4     1175             Delicatessen (1991)  7.238394\n",
       "5       94          Beautiful Girls (1996)  7.238394\n",
       "6      803      Walking and Talking (1996)  7.238394\n",
       "7      195  Something to Talk About (1995)  7.238394\n",
       "8     1457            Fools Rush In (1997)  7.238394\n",
       "9     1784       As Good as It Gets (1997)  7.238394"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "distance_matrix\n",
    "    .where(sql_func.col('one.movieId')==104863)\n",
    "    .orderBy('distance')\n",
    "    .select('two.movieId', 'two.title', 'distance')\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "# определим функцию расстояния\n",
    "distance_cos = sql_func.udf(\n",
    "    lambda x1, x2: minkowski(\n",
    "        x1.toArray(),\n",
    "        x2.toArray()\n",
    "        ), # тут может потребоваться tolist() для некоторых расстояний\n",
    "    returnType=FloatType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_cos = (\n",
    "    tf_idf.alias('one')\n",
    "    .crossJoin(tf_idf.alias('two'))\n",
    "    .select(\n",
    "        'one.movieId',\n",
    "        'one.title',\n",
    "        'two.movieId',\n",
    "        'two.title',\n",
    "        distance_cos('one.tf_idf', 'two.tf_idf').alias('distance_cos')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1347.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 120.0 failed 1 times, most recent failure: Lost task 0.0 in stage 120.0 (TID 3698, localhost, executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:707)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:175)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:99)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:112)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:90)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:89)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\n\tat org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:628)\n\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1433)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1430)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1439)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1426)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3255)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3255)\n\tat sun.reflect.GeneratedMethodAccessor130.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:707)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:175)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:99)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:112)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:90)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:89)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\n\tat org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:628)\n\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1433)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1430)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-b5c0efe183ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distance_cos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'two.movieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'two.title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance_cos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1347.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 120.0 failed 1 times, most recent failure: Lost task 0.0 in stage 120.0 (TID 3698, localhost, executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:707)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:175)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:99)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:112)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:90)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:89)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\n\tat org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:628)\n\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1433)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1430)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1439)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1426)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3255)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3255)\n\tat sun.reflect.GeneratedMethodAccessor130.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:707)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:175)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:99)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:112)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:90)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$evaluate$1.apply(BatchEvalPythonExec.scala:89)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\n\tat org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:628)\n\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1433)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1430)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "distance_matrix_cos\n",
    "    .where(sql_func.col('one.movieId')==778)\n",
    "    .orderBy('distance_cos')\n",
    "    .select('two.movieId', 'two.title', 'distance_cos')\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
